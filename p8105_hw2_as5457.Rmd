---
title: "p8105_hw2_as5457"
author: "Sunny Siddique"
date: "October 1, 2018"
output: github_document
---

Problem 1

```{r}
library(tidyverse)
```


#Problem 1


##Read and clean the data; retain line, station, name, station latitude / longitude, routes served, entry, vending, entrance type, and ADA compliance. Convert the entry variable from character (YES vs NO) to a logical variable (the ifelse or recode function may be useful).

```{r}
transit_data = read_csv(file = "./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
  janitor::clean_names(dat = .) %>% 
  rename (route_1 = route1, route_2 = route2, route_3 = route3, route_4 = route4, route_5 = route5, route_6 = route6, route_7 = route7, route_8 = route8, route_9 = route9, route_10 = route10, route_11 = route11) %>% 
  gather(key = route, value = route_name, route_1:route_11) %>% 
  separate (route, into = c("route_str", "route_number"), sep = "_") %>% 
    select (line, station_name, station_latitude, station_longitude, route_number, route_name, entry, vending, ada) %>% 
  mutate(entry=ifelse(entry=="YES", yes=TRUE, no=FALSE))
```

##Write a short paragraph about this dataset – explain briefly what variables the dataset contains, describe your data cleaning steps so far, and give the dimension (rows x columns) of the resulting dataset. Are these data tidy?

The variables in this dataset provide information regarding the line, name, exact location (latitude/longitude), the name and number of routes available at the station, entry, vending and ADA compliance status. To clean this dataset, I first used the janitor package to change the variable names to lower case and separated by _. Then I renamed the route variables and separated the character variables by underscores to be able to later split it into two variables: route number and route name. I then selected only the variables specified in the prompt and used the mutate and ifthen function to change the character variable "entry" into a logical variable. The dimension of the resulting dataset is `r dim_desc(transit_data)`. These data are tidy in the sense that they meet the following three criteria: columns are variables, rows are observations, every value has a cell (even though not all cells have a value).


##How many distinct stations are there? Note that stations are identified both by name and by line (e.g. 125th St A/B/C/D; 125st 1; 125st 4/5); the distinct function may be useful here.
The number of distinct stations is `r nrow(distinct(transit_data, station_name, line))`.


##How many stations are ADA compliant?

```{r}
station_ADA = transit_data %>% 
  filter (ada == "TRUE") %>% 
  distinct (station_name)
nrow(station_ADA)
```


##What proportion of station entrances / exits without vending allow entrance?

```{r}
vending =
transit_data %>% 
  filter (vending == "NO" & entry == "TRUE") %>% 
  distinct (station_name)
nrow(vending)/nrow(distinct(transit_data, station_name, line))
```

##Reformat data so that route number and route name are distinct variables. How many distinct stations serve the A train? 

```{r}
a_train = transit_data %>% 
  filter (route_name == "A") %>% 
  distinct(station_name)
nrow(a_train)
```

##Of the stations that serve the A train, how many are ADA compliant?

```{r}
ada_comp = transit_data %>% 
  filter (route_name == "A", ada == "TRUE") %>% 
  distinct(station_name)
nrow(ada_comp)
```

#Problem 2

Read and clean the Mr. Trash Wheel sheet:

- specify the sheet in the Excel file and to omit columns containing notes (using the range argument and
##cell_cols() function)
- use reasonable variable names
- omit rows that do not include dumpster-specific data, rounds the number of sports balls to the nearest integer and converts the result to an integer variable (using as.integer)

```{r}
library(readxl)
trash_wheel = readxl::read_excel("./data/HealthyHarborWaterWheelTotals2017-9-26.xlsx", sheet = 1, range = "A2:N258") %>% 
  janitor::clean_names(dat = .) %>% 
  filter(!is.na(dumpster)) %>% 
  mutate (sports_balls = as.integer(round(sports_balls, digits = 0)))
trash_wheel
```

```{r}
as.integer(trash_wheel$sports_balls)
class(trash_wheel$sports_balls)
```

Read and clean precipitation data for 2016 and 2017. For each, omit rows without precipitation data and add a variable year. 

```{r}
prec17 = readxl::read_excel("./data/HealthyHarborWaterWheelTotals2017-9-26.xlsx", sheet = 3, range = "A2:B14") %>% 
  janitor::clean_names(dat = .) %>% 
  filter(!is.na(total))
prec17$year = 2017
```

```{r}
prec16 = readxl::read_excel("./data/HealthyHarborWaterWheelTotals2017-9-26.xlsx", sheet = 4, range = "A2:B14") %>% 
  janitor::clean_names(dat = .) %>% 
  filter(!is.na(total))
prec16$year = 2016
```


##Next, combine datasets and convert month to a character variable (the variable month.name is built into R and should be useful).

```{r}
combined_year = bind_rows(prec16, prec17) %>% 
  mutate (month = month.name[month])
```


Write a paragraph about these data; you are encouraged to use inline R. Be sure to note the number of observations in both resulting datasets, and give examples of key variables. For available data, what was the total precipitation in 2017? What was the median number of sports balls in a dumpster in 2016?

The number of observations in the trashwheel dataset is `r nrow (trash_wheel)`. 
The number of observations in the merged precipitation dataset is `r nrow (combined_year)`. 
The key variables in the trash_wheel dataset include variables that describe the amount of trash that was collected in each dumpster (by weight and volume) and also the various types of trash that were collected (plastic bottles, grocery bags etc.). Key variables in the precipitation dataset include the amount of precipitation in 2016 and 2017. 
Total precipitation in 2017 was `r sum(prec17$total)`.
The median number of sports balls in a dumpster in 2016 was `r median(trash_wheel$sports_balls)`.

#Problem 3

This problem uses the BRFSS data. DO NOT include this dataset in your local data directory; instead, load the data from the  p8105.datasets package.
For this question:

format the data to use appropriate variable names;
focus on the “Overall Health” topic
exclude variables for class, topic, question, sample size, and everything from lower confidence limit to GeoLocation
structure data so that values for Response (“Excellent” to “Poor”) are column names / variables which indicate the proportion of subjects with each response (which are values of Data_value in the original dataset)
create a new variable showing the proportion of responses that were “Excellent” or “Very Good”

```{r}
library(p8105.datasets)
data("brfss_smart2010")
brfss_smart = brfss_smart2010 %>% 
janitor::clean_names(dat = .) %>% 
  filter(topic == "Overall Health") %>% 
  select(year, locationabbr, locationdesc, response, data_value) %>% 
  spread(., key = response, value = data_value) %>% 
  janitor::clean_names() %>% 
  mutate(prop_excellent_vgood = excellent + very_good)
  
```



##How many unique locations are included in the dataset? Is every state represented? What state is observed the most?

The number of unique locations is `r length(unique(brfss_smart$locationabbr))`. This includes all 50 states and Washington DC. The state that is observed the most is `r tail(names(sort(table(brfss_smart$locationabbr))), 1)`.



##In 2002, what is the median of the “Excellent” response value?



Make a histogram of “Excellent” response values in the year 2002.

```{r}
library(ggridges)
```


```{r}
excellent_hist = brfss_smart %>% 
  filter(year == 2002) %>% 
  ggplot(., aes(x = excellent)) + 
  geom_histogram()
excellent_hist
```


Make a scatterplot showing the proportion of “Excellent” response values in New York County and Queens County (both in NY State) in each year from 2002 to 2010.

```{r}
ny_county = brfss_smart %>% 
  filter(locationdesc == "NY - New York County")
queens_county = brfss_smart %>%
  filter(locationdesc == "NY - Queens County")
combined_county = bind_rows(ny_county, queens_county)
ggplot(combined_county, aes(x = year, y = excellent)) + 
  geom_point(aes(color = locationdesc))
```





